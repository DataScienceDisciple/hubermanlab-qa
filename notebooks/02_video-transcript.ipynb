{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import googleapiclient.discovery\n",
    "import re\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel\n",
    "from youtube_transcript_api import YouTubeTranscriptApi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Get transcripts from a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_any(string, phrases):\n",
    "    return any(phrase in string for phrase in phrases)\n",
    "\n",
    "def get_transcript_segments(video_id, video_title):\n",
    "  # Set up the API key and service object.\n",
    "  api_service_name = \"youtube\"\n",
    "  api_version = \"v3\"\n",
    "  youtube = googleapiclient.discovery.build(\n",
    "      api_service_name, api_version, developerKey=API_KEY)\n",
    "\n",
    "  # Call the YouTube API to retrieve the metadata of the video.\n",
    "  request = youtube.videos().list(\n",
    "      part=\"id,snippet,contentDetails,statistics\",\n",
    "      id=video_id\n",
    "  )\n",
    "  response = request.execute()\n",
    "\n",
    "  # Retrieve the segments from the video description.\n",
    "  segments = []\n",
    "  titles = []\n",
    "  if 'description' in response['items'][0]['snippet']:\n",
    "    description = response['items'][0]['snippet']['description']\n",
    "    lines = description.split(\"\\n\")\n",
    "    for line in lines:\n",
    "      timestamp_match = re.search(r\"\\d+:\\d+:\\d+|\\d+:\\d+\", line)\n",
    "      if timestamp_match:\n",
    "        segments.append(timestamp_match.group())\n",
    "        titles.append(line[timestamp_match.end():][1:])\n",
    "\n",
    "  # Retrieve the transcript of the video.\n",
    "  transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "\n",
    "  sponsor_segment_phrases = [\"AG1\", \"Athletic Greens\", \"Inside Tracker\", \"Sponsors\", \"Sponsor\", \"ROKA\", \"Levels\", \"Magic Spoon\", \"Blinkist\"]\n",
    "\n",
    "  # Iterate through the items in the transcript and match them with the relevant segments.\n",
    "  matched_segments = {}\n",
    "  for i in range(len(segments) - 1):\n",
    "    start_segment = segments[i]\n",
    "    end_segment = segments[i+1]\n",
    "    if not contains_any(titles[i], sponsor_segment_phrases):\n",
    "      segment_title = titles[i][:100]\n",
    "      key_title = f\"Episode {video_title}, Segment {segment_title} ({start_segment} {end_segment})\".replace(\"/\", \" \").replace(\":\", \"-\")\n",
    "      matched_segments[key_title] = []\n",
    "      for item in transcript:\n",
    "        start_time = item['start']\n",
    "        end_time = item['start'] + item['duration']\n",
    "        if start_time >= to_seconds(start_segment) and end_time <= to_seconds(end_segment):\n",
    "          matched_segments[key_title].append(item['text'])\n",
    "  for title, text in matched_segments.items():\n",
    "    matched_segments[title] = ' '.join(text).replace('\\n',' ')\n",
    "  return matched_segments\n",
    "\n",
    "def to_seconds(timestamp):\n",
    "  parts = list(map(int, timestamp.split(\":\")))\n",
    "  if len(parts) == 2:\n",
    "    return parts[0] * 60 + parts[1]\n",
    "  elif len(parts) == 3:\n",
    "    return parts[0] * 3600 + parts[1] * 60 + parts[2]\n",
    "  \n",
    "def save_segments_to_txt(matched_segments):\n",
    "  for title, text in matched_segments.items():\n",
    "    print(title)\n",
    "    with open(f\"../data/transcripts/{title}.txt\", \"w\") as f:\n",
    "      f.write(text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "video_data = pd.read_csv('../data/video_metadata.csv')\n",
    "# Replace the API key below with a valid API key.\n",
    "API_KEY = json.load(open('../config/yt_api.json', 'r'))['YT_API_KEY']\n",
    "\n",
    "# Replace the video ID below with a valid video ID.\n",
    "VIDEO_ID = video_data.loc[0, 'videoId']\n",
    "VIDEO_TITLE = video_data.loc[0, 'title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving all podcast segments to files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_videos = []\n",
    "for key, item in video_data.iterrows():\n",
    "    video_id = item['videoId']\n",
    "    video_title = item['title']\n",
    "    print(video_title)\n",
    "    try:\n",
    "        matched_segments = get_transcript_segments(video_id, video_title)\n",
    "    except:\n",
    "        print(f\"Video failed: {video_title}\")\n",
    "        failed_videos.append(video_title)\n",
    "    save_segments_to_txt(matched_segments)\n",
    "print(matched_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_videos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
